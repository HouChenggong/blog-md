## NLP å­¦ä¹ è®°å½•

- Standfordmlpå­¦ä¹ å‚è€ƒåœ°å€ï¼š[æç†çš„åšå®¢](https://fancyerii.github.io/books/stanfordnlp/)
- Githubåœ°å€ï¼š[æç†çš„åšå®¢Javaä»£ç åœ°å€](https://github.com/fancyerii/blog-codes/tree/master/stanfordnlp)
- Nlp downloadåœ°å€ï¼šhttps://stanfordnlp.github.io/CoreNLP/history.html
- NLP jar åŒ…ä¸‹è½½åœ°å€ã€‚https://repo1.maven.org/maven2/edu/stanford/nlp/stanford-corenlp/3.9.2/
- [NLP demo](https://stanfordnlp.github.io/CoreNLP/demo.html)
- [NLP pipeline](https://stanfordnlp.github.io/CoreNLP/pipeline.html)
- 

### Java mavenç¯å¢ƒ

```java
<project xmlns="http://maven.apache.org/POM/4.0.0"
	xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd">
	<modelVersion>4.0.0</modelVersion>
	<groupId>com.fancyerii.blog</groupId>
	<artifactId>stanfordnlp</artifactId>
	<packaging>jar</packaging>
	<version>1.0-SNAPSHOT</version>
	<name>stanfordnlp</name>
	<url>http://maven.apache.org</url>
	<properties>
		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
		<java.version>1.8</java.version>
	</properties>
	<dependencies>
		<dependency>
			<groupId>ch.qos.logback</groupId>
			<artifactId>logback-classic</artifactId>
			<version>1.2.3</version>
		</dependency>
		<dependency>
			<groupId>junit</groupId>
			<artifactId>junit</artifactId>
			<version>4.11</version>
			<scope>test</scope>
		</dependency>
		<dependency>
			<groupId>edu.stanford.nlp</groupId>
			<artifactId>stanford-corenlp</artifactId>
			<version>3.9.2</version>
		</dependency>
		<dependency>
			<groupId>edu.stanford.nlp</groupId>
			<artifactId>stanford-corenlp</artifactId>
			<version>3.9.2</version>
			<classifier>models</classifier>
		</dependency>
		<dependency>
			<groupId>edu.stanford.nlp</groupId>
			<artifactId>stanford-corenlp</artifactId>
			<version>3.9.2</version>
			<classifier>models-chinese</classifier>
		</dependency>
		<dependency>
			<groupId>commons-io</groupId>
			<artifactId>commons-io</artifactId>
			<version>2.6</version>
		</dependency>

	</dependencies>
	<build>
		<plugins>
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-compiler-plugin</artifactId>
				<configuration>
					<source>${java.version}</source>
					<target>${java.version}</target>
					<showDeprecation>true</showDeprecation>
					<showWarnings>true</showWarnings>
					<executable>${env.JAVA_HOME}/bin/javac</executable>
					<fork>true</fork>
				</configuration>
			</plugin>
			<plugin>
				<artifactId>maven-assembly-plugin</artifactId>
				<configuration>
					<descriptorRefs>
						<descriptorRef>jar-with-dependencies</descriptorRef>
					</descriptorRefs>
				</configuration>
			</plugin>
		</plugins>
	</build>
</project>

```

### standfordnlp

### å¸¸è§åè¯

##### Annotationæ³¨é‡Š

Annotationå¯ä»¥çœ‹æˆä¸€ä¸ªMapï¼ŒValueæ˜¯ä¸€ä¸ªStringï¼Œè¡¨ç¤ºè¾“å…¥çš„æ–‡æœ¬

##### Annotatoræ³¨é‡Šå™¨

##### tokenize

##### ssplit åˆ†å¥

##### posè¯æ€§æ ‡æ³¨

##### nerç”¨äºå®ç°å‘½åå®ä½“è¯†åˆ«,æ¯”å¦‚åœ°åã€æ—¶é—´å¹´æœˆæ—¥ç­‰è¯

##### egexNER  

æˆ‘ä»¬è¿˜å¯ä»¥ä½¿ç”¨[RegexNER](https://nlp.stanford.edu/software/regexner.html)æ¥è‡ªå·±å®šä¹‰è¯†åˆ«å®ä½“çš„è§„åˆ™ã€‚RegexNerç±»ä¼¼ä¸æ­£åˆ™è¡¨è¾¾å¼ï¼Œä½†æ˜¯å®ƒæ˜¯åŸºäºToken(è¯)è€Œä¸æ˜¯å­—ç¬¦ä¸²çš„(å› æ­¤ä¸å¤ªé€‚åˆä¸­æ–‡)ã€‚

##### Parser å®ç°æˆåˆ†å¥æ³•åˆ†æã€‚

##### depparse ç”¨äºå®ç°ä¾å­˜å¥æ³•åˆ†æ

##### coref ç”¨äºå®ç°æŒ‡ä»£æ¶ˆè§£

åœ¨ä¸€ä¸ªæ–‡æœ¬ä¸­çš„å¯èƒ½æœ‰å¤šä¸ªå®ä½“è¡¨ç¤ºçš„æ˜¯ç‰©ç†å®é™…ä¸­çš„ç›¸åŒå®ä½“ï¼Œæˆ‘ä»¬éœ€è¦æ‰¾å‡ºè¿™ç§å…³ç³»æ¥ã€‚

æ¯”å¦‚æ–‡æœ¬â€Barack Obama was born in Hawaii. He is the president. Obama was elected in 2008.â€ï¼Œå®ä½“**Barack Obama**å’Œ**He**ä»¥åŠ**Obama**éƒ½æ˜¯æŒ‡ä»£é€šä¸€ä¸ªäººã€‚

##### sentimentç”¨äºæƒ…æ„Ÿåˆ†æâ€”â€”ZHä¸æ”¯æŒ



#### è‹±æ–‡åˆ†è¯

- [å‚è€ƒåœ°å€](https://fancyerii.github.io/books/stanfordnlp/)

```java
import edu.stanford.nlp.ling.*;
import edu.stanford.nlp.pipeline.*;
import edu.stanford.nlp.util.*;

import java.util.*;

public class PipelineDemo {

    public static void main(String[] args) {
        //ä»£ç é¦–å…ˆæ„é€ Propertieså¯¹è±¡ï¼Œ
        Properties props = new Properties();

        // ä¸‹é¢çš„ä»£ç æ˜¯æœ‰é—®é¢˜çš„ã€‚
        // props.setProperty("annotators", "ssplit,tokenize");
        //ç„¶åè®¾ç½®ä½¿ç”¨çš„annotatorsä¸ºâ€tokenize,ssplitâ€ï¼Œè¡¨ç¤ºåªåˆ†è¯å’Œåˆ†å¥ã€‚
        props.setProperty("annotators", "tokenize,ssplit");

        // æ„é€ Pipeline
        StanfordCoreNLP pipeline = new StanfordCoreNLP(props);

        // æ„é€ ä¸€ä¸ªCoreDocumentå¯¹è±¡ï¼Œä¼ å…¥è¦åˆ†æçš„æ–‡æœ¬
        CoreDocument exampleDocument = new CoreDocument("Here is the text to tokenize.");
        // annotate document ç„¶åä½¿ç”¨pipeline.annotateæ–¹æ³•å°±å¯ä»¥äº†
        pipeline.annotate(exampleDocument);
        // exampleDocument.sentences()å¯ä»¥æ‹¿åˆ°æ‰€æœ‰çš„å¥å­ï¼Œæˆ‘ä»¬è¿™é‡Œåªæœ‰ä¸€ä¸ªå¥å­ï¼Œå› æ­¤å¯ä»¥å†ç”¨get(0)æ‹¿åˆ°ç¬¬ä¸€ä¸ªå¥å­çš„å¤„ç†ç»“æœ
        List<CoreLabel> firstSentenceTokens = exampleDocument.sentences().get(0).tokens();
        // ä¸€ä¸ªå¥å­åˆæœ‰å¾ˆå¤šTokenï¼Œå› æ­¤è°ƒç”¨tokens()æ–¹æ³•æ‹¿åˆ°å¤šä¸ªToken(List)ã€‚
        for (CoreLabel token : firstSentenceTokens) {
            //æˆ‘ä»¬å¯ä»¥ä»ä¸­æ‹¿åˆ°è¯(token.word())ã€å¼€å§‹ä¸‹æ ‡(token.beginPosition())å’Œç»“æŸä¸‹æ ‡(token.endPosition())ã€‚
            System.out.println(token.word() + "\t" + token.beginPosition() + "\t" + token.endPosition());
        }

    }
}
```

##### ssplit

ssplitå¯¹åº”çš„æ˜¯WordsToSentenceAnnotatorï¼Œå®ƒå®ç°çš„æ˜¯åˆ†å¥çš„åŠŸèƒ½ã€‚å‰é¢æˆ‘ä»¬å…¶å®å·²ç»ç”¨åˆ°äº†åˆ†å¥ï¼Œæˆ‘ä»¬åœ¨ä¸‹é¢çš„ä»£ç é‡ŒæŒ‡å®šäº†æˆ‘ä»¬çš„PipeLineæ˜¯å…ˆåˆ†è¯ååˆ†å¥ï¼š

```java
props.setProperty("annotators", "tokenize,ssplit");
```

å¦‚æœæ¢æˆ

```java
props.setProperty("annotators", "ssplit,tokenize");
```

åˆ™ä¼šæŠ›å‡ºå¼‚å¸¸ï¼Œæç¤ºannotator â€œssplitâ€ requires annotation â€œTextAnnotationâ€ã€‚æˆ‘ä»¬çŸ¥é“TextAnnotationæ˜¯tokenizeçš„ç»“æœä¹‹ä¸€(è¿˜æœ‰tokençš„ä½ç½®ç­‰å…¶å®ƒç»“æœ)ï¼Œå› æ­¤åˆ†å¥æ˜¯ä¾èµ–åˆ†è¯çš„ã€‚

æœ‰äº›è¯»è€…å¯èƒ½å¥‡æ€ªï¼Œä¸ºä»€ä¹ˆåˆ†è¯åœ¨åˆ†å¥ä¹‹å‰å‘¢ï¼Ÿå¯¹äºè‹±æ–‡æ¥è¯´ï¼Œåˆ†å¥ä¸»è¦ä¾èµ–ä¸€äº›æ ‡ç‚¹ç¬¦å·ï¼Œæ¯”å¦‚â€,.!?â€ç­‰ã€‚ä½†æ˜¯è‹±æ–‡æœ‰äº›å•è¯æ¯”å¦‚â€Mr. St.â€æ˜¯åŒ…å«ä»¥è‹±æ–‡å¥å·çš„ï¼Œå¦‚æœç›´æ¥ç”¨æ ‡ç‚¹åˆ†å¥ä¼šæœ‰é—®é¢˜ï¼Œå› æ­¤Stanford CoreNLPé¦–å…ˆåˆ†è¯ï¼Œåˆ†å®Œè¯åå°±å¯ä»¥ç”¨æ ‡ç‚¹åˆ†å¥ã€‚ä½†æ˜¯è¿™å¯¹ä¸­æ–‡å¹¶ä¸åˆé€‚ï¼Œå› ä¸ºè‹±æ–‡çš„åˆ†è¯æ˜¯åŸºäºè§„åˆ™(çŠ¶æ€æœº)ï¼Œå®ƒçš„æ—¶é—´å¤æ‚åº¦æ˜¯O(n)çš„ã€‚è€Œä¸­æ–‡æ˜¯ä½¿ç”¨CRFsæ¨¡å‹ï¼Œå®ƒåœ¨é¢„æµ‹æ˜¯æ—¶ä½¿ç”¨åŠ¨æ€è§„åˆ’æ¥è§£ç ï¼Œå…¶å¤æ‚åº¦æ˜¯ğ‘‚(ğ‘›2)O(n2)ã€‚ä¸­æ–‡æˆ‘ä»¬æ›´é€‚åˆå…ˆåˆ†å¥åœ¨åˆ†è¯ï¼Œå› æ­¤å¯¹äºä¸­æ–‡ï¼Œæˆ‘ä»¬é€šå¸¸å…ˆè‡ªè¡Œåˆ†å¥ï¼Œç„¶åç”¨Pipelineæ¥å¤„ç†æ¯ä¸€ä¸ªå¥å­ã€‚ä¸ºäº†é¿å…CoreNLPå†åˆ†å¥ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨Propertiesé‡Œè®¾ç½®ssplit.isOneSentenceä¸ºTrueï¼Œåˆ™å®ƒå°±æŠŠè¾“å…¥çš„æ–‡æœ¬å½“æˆä¸€ä¸ªå¥å­å¤„ç†ã€‚

- ç®€å•çš„è‹±æ–‡åˆ†è¯

```java
import java.io.IOException;
import java.io.Reader;
import java.io.StringReader;

import edu.stanford.nlp.ling.CoreLabel;
import edu.stanford.nlp.process.CoreLabelTokenFactory;
import edu.stanford.nlp.process.PTBTokenizer;

public class TokenizerDemo {

    public static void main(String[] args) throws IOException {
        String paragraph = "My 1st sentence. â€œDoes it work for questions?â€ My third sentence.";
        Reader reader = new StringReader(paragraph);
        // option #2: By token
        PTBTokenizer<CoreLabel> ptbt = new PTBTokenizer<>(reader, new CoreLabelTokenFactory(), "");
        while (ptbt.hasNext()) {
            CoreLabel label = ptbt.next();
            System.out.println(label);
        }

    }
}
```



#### ä¸­æ–‡åˆ†è¯

[ä¸­æ–‡åˆ†è¯å‚è€ƒåœ°å€](https://blog.csdn.net/macanv/article/details/72993873)

#### POS è¯æ€§æ ‡æ³¨

```java

import java.io.InputStream;
import java.io.StringReader;
import java.util.List;

import edu.stanford.nlp.ling.HasWord;
import edu.stanford.nlp.ling.SentenceUtils;
import edu.stanford.nlp.ling.TaggedWord;
import edu.stanford.nlp.tagger.maxent.MaxentTagger; 

public class TaggerDemo {

	private TaggerDemo() {
	}

	public static void main(String[] args) throws Exception { 
		InputStream input = TaggerDemo.class.getResourceAsStream("/"+MaxentTagger.DEFAULT_JAR_PATH);
 
		MaxentTagger tagger = new MaxentTagger(input);
		
		List<List<HasWord>> sentences = MaxentTagger.tokenizeText(new StringReader("Karma of humans is AI"));

		for (List<HasWord> sentence : sentences) {

			List<TaggedWord> tSentence = tagger.tagSentence(sentence);

			System.out.println(SentenceUtils.listToString(tSentence, false));

		}

	}

}
//Karma of humans is AI ç»“æœæ˜¯ï¼š
//Karma/NN of/IN humans/NNS is/VBZ AI/NNP
```

##### NLTK è¯æ€§æ ‡æ³¨

æ„Ÿå…´è¶£çš„å¯ä»¥æœç´¢ä¸‹NLTK è¯æ€§æ ‡æ³¨ï¼Œå…¶å®å°±æ˜¯æ ‡ç¤ºå‡ºä¸€ä¸ªè¯æ˜¯ï¼šåç§°ã€åŠ¨è¯ã€å½¢å®¹è¯ã€å‰¯è¯ã€æ„Ÿå¹è¯ç­‰

[NLTKä¸€äº›å¸¸è§çš„åˆ†ç±»](https://www.cnblogs.com/elpsycongroo/p/9369111.html)

- NN å¸¸ç”¨åè¯ å•æ•°å½¢å¼

- NNPä¸“æœ‰åè¯

- IN ä»‹è¯æˆ–ä»å±è¿è¯

- NNS å¸¸ç”¨åç§°ï¼Œå¤æ•°å½¢å¼

- VBZ åŠ¨è¯ç¬¬ä¸‰äººç§°å•æ•°

  

#### parseræˆåˆ†è¯­æ³•åˆ†æ

```java

import edu.stanford.nlp.ling.CoreAnnotations;
import edu.stanford.nlp.pipeline.Annotation;
import edu.stanford.nlp.pipeline.StanfordCoreNLP;
import edu.stanford.nlp.trees.*;

import java.util.*;

public class ConstituentExample {

	public static void main(String[] args) {
		// set up pipeline properties
		Properties props = new Properties();
		props.setProperty("annotators", "tokenize,ssplit,pos,lemma,ner,parse");
		// use faster shift reduce parser
		//props.setProperty("parse.model", "edu/stanford/nlp/models/srparser/englishSR.ser.gz");
		props.setProperty("parse.maxlen", "100");
		// set up Stanford CoreNLP pipeline
		StanfordCoreNLP pipeline = new StanfordCoreNLP(props);
		// build annotation for a review
		Annotation annotation = new Annotation("The small red car turned very quickly around the corner.");
		// annotate
		pipeline.annotate(annotation);
		// get tree
		Tree tree = annotation.get(CoreAnnotations.SentencesAnnotation.class).get(0)
				.get(TreeCoreAnnotations.TreeAnnotation.class);
		System.out.println(tree);
    //æ¥ç€ä½¿ç”¨â€Set treeConstituents = tree.constituents(new LabeledScoredConstituentFactory());
    //"æ¥å¾—åˆ°å¥æ³•æ ‘çš„æ¯ä¸€ä¸ªæˆåˆ†ï¼Œç„¶åå¯»æ‰¾VPå’ŒNPã€‚
		Set<Constituent> treeConstituents = tree.constituents(new LabeledScoredConstituentFactory());
		for (Constituent constituent : treeConstituents) {
			if (constituent.label() != null
					&& (constituent.label().toString().equals("VP") || constituent.label().toString().equals("NP"))) {
				System.err.println("found constituent: " + constituent.toString());
				System.err.println(tree.getLeaves().subList(constituent.start(), constituent.end() + 1));
			}
		}
	}
}
```

- è¾“å‡ºçš„ç»“æœæ˜¯ï¼šå¯ä»¥å‚è€ƒè¿™ä¸ªåœ°å€çš„å›¾[treeå›¾](http://fancyerii.github.io/books/stanfordnlp/#java-client)

```java
(ROOT (S (NP (DT The) (JJ small) (JJ red) (NN car)) (VP (VBD turned) (ADVP (RB very) (RB quickly)) (PP (IN around) (NP (DT the) (NN corner)))) (. .)))
found constituent: NP(0,3)
[The, small, red, car]
found constituent: NP(8,9)
[the, corner]
found constituent: VP(4,9)
[turned, very, quickly, around, the, corner]
```

#### è·å–è‹±æ–‡ä¸­çš„åè¯

```java

import edu.stanford.nlp.parser.lexparser.LexicalizedParser;
import edu.stanford.nlp.trees.EnglishGrammaticalStructure;
import edu.stanford.nlp.trees.Tree;
import edu.stanford.nlp.trees.TypedDependency;

import java.util.Collection;

// åˆ©ç”¨stanford parseè¿›è¡Œå¤„ç†ï¼Œè·å–åè¯é›†åˆ
public class NounAnalyzer {

    private static String model = "edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz";
    
    public String analyze(String temple, String model) {
        LexicalizedParser parser = LexicalizedParser.loadModel(model);
        // åˆ©ç”¨parserè·å–è¯æ€§å¹¶è¾“å‡ºtempleä¸­çš„åè¯
        // ç”¨é€—å·åˆ†å‰²
        StringBuffer sb = new StringBuffer();

        Tree t = parser.parse(temple);
        //è‹±è¯­è¯­æ³•ç»“æ„
        EnglishGrammaticalStructure es = new EnglishGrammaticalStructure(t);
        //ä¾å­˜å…³ç³»,è·å–tdå…³ç³»ç»„åˆ
        Collection<TypedDependency> tdl = es.typedDependencies();
        for (int i = 0; i < tdl.size(); i++) {
            TypedDependency td = (TypedDependency) tdl.toArray()[i];
            String word = td.dep().word();
            String tag = td.dep().tag();
            if (tag.contains("NN")) {
                //åè¯
                sb.append(word).append(",");
            }
        }
        return sb.toString();
    }

    public static void main(String[] args) {
        NounAnalyzer analyzer = new NounAnalyzer();
        String msg = "this is a apple and its name is xiaopingguo";
        String result = analyzer.analyze(msg, model);
        System.out.println(result);
    }
}
//apple,name,xiaopingguo,
```



#### å°†æ–‡æœ¬å˜æˆå¤šä¸ªå¥å­

```java
import java.io.IOException;
import java.io.Reader;
import java.io.StringReader;
import java.util.List;

import edu.stanford.nlp.ling.HasWord;
import edu.stanford.nlp.process.DocumentPreprocessor;

public class TokenizerDemo {

    public static void main(String[] args) throws IOException {
        String paragraph = "My 1st sentence. â€œDoes it work for questions?â€ My third sentence.";
        Reader reader = new StringReader(paragraph);
        Reader reader2 = new StringReader(paragraph);

        // option #1: By sentence.
        DocumentPreprocessor dp = new DocumentPreprocessor(reader);
        for (List<HasWord> sentence : dp) {
            System.out.println(sentence);
        }
    }

}
```

- ç»“æœæ˜¯ï¼š

```java
[My, 1st, sentence, .]
[``, Does, it, work, for, questions, ?, '']
[My, third, sentence, .]
```

#### lexparser

```java

import edu.stanford.nlp.parser.lexparser.LexicalizedParser;
import edu.stanford.nlp.trees.EnglishGrammaticalStructure;
import edu.stanford.nlp.trees.Tree;
import edu.stanford.nlp.trees.TypedDependency;
import edu.stanford.nlp.trees.international.pennchinese.ChineseGrammaticalStructure;

import java.util.Collection;

// åˆ©ç”¨stanford parseè¿›è¡Œå¤„ç†ï¼Œè·å–åè¯é›†åˆ
public class NounAnalyzer {


    public String analyEnglish(String content) {
        String model = "edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz";
        LexicalizedParser parser = LexicalizedParser.loadModel(model);
        // åˆ©ç”¨parserè·å–è¯æ€§å¹¶è¾“å‡ºtempleä¸­çš„åè¯
        // ç”¨é€—å·åˆ†å‰²
        StringBuffer sb = new StringBuffer();
        Tree t = parser.parse(content);
        //è‹±è¯­è¯­æ³•ç»“æ„
        EnglishGrammaticalStructure es = new EnglishGrammaticalStructure(t);
        //ä¾å­˜å…³ç³»,è·å–tdå…³ç³»ç»„åˆ
        Collection<TypedDependency> tdl = es.typedDependencies();
        System.out.println(tdl.toString());
        for (int i = 0; i < tdl.size(); i++) {
            TypedDependency td = (TypedDependency) tdl.toArray()[i];
            String word = td.dep().word();
            String tag = td.dep().tag();
            if (tag.contains("NN")) {
                //åè¯
                sb.append(word).append(",");
            }
        }
        return sb.toString();
    }

    public String analyChinese(String content) {
        String model = "edu/stanford/nlp/models/lexparser/chinesePCFG.ser.gz";
        LexicalizedParser parser = LexicalizedParser.loadModel(model);
        Tree t = parser.parse(content);
        ChineseGrammaticalStructure gs = new ChineseGrammaticalStructure(t);
        Collection<TypedDependency> tdl = gs.typedDependenciesCCprocessed();
        return tdl.toString();
    }

    public static void main(String[] args) {
        NounAnalyzer analyzer = new NounAnalyzer();
        String msg = "this is a apple and its name is xiaopingguo";
        String result = analyzer.analyEnglish(msg);
        System.out.println(result);
        // å·²ç»åˆ†å¥½è¯äº†
        String msgZh = "ç»Ÿè®¡ è¿˜ æ˜¾ç¤º ï¼Œ å°å•† æŠ•èµ„ ç¥–å›½ å¤§é™† æ­£ è¶‹å‘ å¤§å‹åŒ– ã€‚";
        String resultZh = analyzer.analyChinese(msgZh);
        System.out.println(resultZh);
    }
}


```

- ä¸Šè¯‰çš„ç»“æœ

```java
[nsubj(is-2, this-1), root(ROOT-0, is-2), det(apple-4, a-3), nsubj(xiaopingguo-9, apple-4), cc(apple-4, and-5), poss(name-7, its-6), conj(apple-4, name-7), cop(xiaopingguo-9, is-8), ccomp(is-2, xiaopingguo-9)]
apple,name,xiaopingguo,
2020-11-20 19:36:24.562 [main] INFO  e.s.n.p.lexparser.LexicalizedParser - Loading parser from serialized file edu/stanford/nlp/models/lexparser/chinesePCFG.ser.gz ... done [0.8 sec].
[nsubj(æ˜¾ç¤º-3, ç»Ÿè®¡-1), advmod(æ˜¾ç¤º-3, è¿˜-2), root(ROOT-0, æ˜¾ç¤º-3), nn(å¤§é™†-8, å°å•†-5), nn(å¤§é™†-8, æŠ•èµ„-6), nn(å¤§é™†-8, ç¥–å›½-7), nsubj(è¶‹å‘-10, å¤§é™†-8), advmod(è¶‹å‘-10, æ­£-9), conj(æ˜¾ç¤º-3, è¶‹å‘-10), dobj(è¶‹å‘-10, å¤§å‹åŒ–-11)]

```



#### ä¸­æ–‡å‘½åä½“è¯†åˆ«

```java

import java.util.List;
import java.util.Map;
import java.util.Properties;

import edu.stanford.nlp.coref.CorefCoreAnnotations;
import edu.stanford.nlp.coref.data.CorefChain;
import edu.stanford.nlp.ling.CoreAnnotations;
import edu.stanford.nlp.ling.CoreLabel;
import edu.stanford.nlp.pipeline.Annotation;
import edu.stanford.nlp.pipeline.StanfordCoreNLP;
import edu.stanford.nlp.semgraph.SemanticGraph;
import edu.stanford.nlp.semgraph.SemanticGraphCoreAnnotations;
import edu.stanford.nlp.trees.Tree;
import edu.stanford.nlp.trees.TreeCoreAnnotations;
import edu.stanford.nlp.util.CoreMap;

/**
 * Created by sonofelice on 2018/3/27.
 * è¿›è¡Œä¸­æ–‡å‘½åå®ä½“è¯†åˆ«(NER)
 */
public class TestNLP {
    public void test() throws Exception {
        //æ„é€ ä¸€ä¸ªStanfordCoreNLPå¯¹è±¡ï¼Œé…ç½®NLPçš„åŠŸèƒ½ï¼Œå¦‚lemmaæ˜¯è¯å¹²åŒ–ï¼Œneræ˜¯å‘½åå®ä½“è¯†åˆ«ç­‰
        Properties props = new Properties();
        props.load(this.getClass().getResourceAsStream("/StanfordCoreNLP-chinese.properties"));
        StanfordCoreNLP pipeline = new StanfordCoreNLP(props);
        String text = "è¢éš†å¹³æ˜¯ä¸­å›½ç§‘å­¦é™¢çš„é™¢å£«,ä»–äº2009å¹´10æœˆåˆ°ä¸­å›½å±±ä¸œçœä¸œè¥å¸‚ä¸œè¥åŒºæ°¸ä¹æœºåœºé™„è¿‘æ‰¿åŒ…äº†ä¸€åƒäº©ç›ç¢±åœ°,"
                + "å¼€å§‹ç§æ¤æ£‰èŠ±, å¹´äº§é‡è¾¾åˆ°ä¸€ä¸‡å¨, å“ˆå“ˆ, åæ­£æ££ç¦è¯´çš„æ˜¯å‡çš„,é€—ä½ ç©å„¿,æ˜å¤©ä¸‹åˆ2ç‚¹æ¥æˆ‘å®¶åƒé¥­å§ã€‚"
                + "æ££ç¦æ˜¯å±±ä¸œå¤§å­¦æ¯•ä¸šçš„,ç›®å‰åœ¨ç™¾åº¦åšjavaå¼€å‘,ä½ç½®æ˜¯ä¸œåŒ—æ—ºä¸œè·¯102å·é™¢,æ‰‹æœºå·14366778890";

        long startTime = System.currentTimeMillis();
        System.out.println(".............å¼€å§‹ï¼š"+startTime);
        // åˆ›é€ ä¸€ä¸ªç©ºçš„Annotationå¯¹è±¡
        Annotation document = new Annotation(text);

        // å¯¹æ–‡æœ¬è¿›è¡Œåˆ†æ
        pipeline.annotate(document);
        System.out.println(".............å¼€å§‹åˆ†æï¼š");
        //è·å–æ–‡æœ¬å¤„ç†ç»“æœ
        List<CoreMap> sentences = document.get(CoreAnnotations.SentencesAnnotation.class);
        for (CoreMap sentence : sentences) {
            // traversing the words in the current sentence
            // a CoreLabel is a CoreMap with additional token-specific methods
            for (CoreLabel token : sentence.get(CoreAnnotations.TokensAnnotation.class)) {
                //                // è·å–å¥å­çš„tokenï¼ˆå¯ä»¥æ˜¯ä½œä¸ºåˆ†è¯åçš„è¯è¯­ï¼‰
                String word = token.get(CoreAnnotations.TextAnnotation.class);
                System.out.println(word);
                //è¯æ€§æ ‡æ³¨
                String pos = token.get(CoreAnnotations.PartOfSpeechAnnotation.class);
                System.out.println(pos);
                // å‘½åå®ä½“è¯†åˆ«
                String ne = token.get(CoreAnnotations.NormalizedNamedEntityTagAnnotation.class);
                String ner = token.get(CoreAnnotations.NamedEntityTagAnnotation.class);
                System.out.println(word + " | analysis : {  original : " + ner + "," + " normalized : "
                        + ne + "}");
                //è¯å¹²åŒ–å¤„ç†
                String lema = token.get(CoreAnnotations.LemmaAnnotation.class);
                System.out.println(lema);
            }

            // å¥å­çš„è§£ææ ‘
            Tree tree = sentence.get(TreeCoreAnnotations.TreeAnnotation.class);
            System.out.println("å¥å­çš„è§£ææ ‘:");
            tree.pennPrint();

            // å¥å­çš„ä¾èµ–å›¾
            SemanticGraph graph =
                    sentence.get(SemanticGraphCoreAnnotations.CollapsedCCProcessedDependenciesAnnotation.class);
            System.out.println("å¥å­çš„ä¾èµ–å›¾");
            System.out.println(graph.toString(SemanticGraph.OutputFormat.LIST));

        }

        long endTime = System.currentTimeMillis();
        long time = endTime - startTime;
        System.out.println("The analysis lasts " + time + " seconds * 1000");

        // æŒ‡ä»£è¯é“¾
        //æ¯æ¡é“¾ä¿å­˜æŒ‡ä»£çš„é›†åˆ
        // å¥å­å’Œåç§»é‡éƒ½ä»1å¼€å§‹
        Map<Integer, CorefChain> corefChains = document.get(CorefCoreAnnotations.CorefChainAnnotation.class);
        if (corefChains == null) {
            return;
        }
        for (Map.Entry<Integer, CorefChain> entry : corefChains.entrySet()) {
            System.out.println("Chain " + entry.getKey() + " ");
            for (CorefChain.CorefMention m : entry.getValue().getMentionsInTextualOrder()) {
                // We need to subtract one since the indices count from 1 but the Lists start from 0
                List<CoreLabel> tokens = sentences.get(m.sentNum - 1).get(CoreAnnotations.TokensAnnotation.class);
                // We subtract two for end: one for 0-based indexing, and one because we want last token of mention
                // not one following.
                System.out.println(
                        "  " + m + ", i.e., 0-based character offsets [" + tokens.get(m.startIndex - 1).beginPosition()
                                +
                                ", " + tokens.get(m.endIndex - 2).endPosition() + ")");
            }
        }
    }

    public static void main(String[] args) throws Exception {
        TestNLP nlp = new TestNLP();
        nlp.test();
    }
}
```

- éœ€è¦åœ¨springboot. resource ç›®å½•ä¸‹æ·»åŠ çš„æ–‡ä»¶

  StanfordCoreNLP-chinese.properties

```properties
# Pipeline options - lemma is no-op for Chinese but currently needed because coref demands it (bad old requirements system)
annotators = tokenize, ssplit, pos, lemma, ner, parse, coref

# segment
tokenize.language = zh
segment.model = edu/stanford/nlp/models/segmenter/chinese/ctb.gz
segment.sighanCorporaDict = edu/stanford/nlp/models/segmenter/chinese
segment.serDictionary = edu/stanford/nlp/models/segmenter/chinese/dict-chris6.ser.gz
segment.sighanPostProcessing = true

# sentence split
ssplit.boundaryTokenRegex = [.ã€‚]|[!?ï¼ï¼Ÿ]+

# pos
pos.model = edu/stanford/nlp/models/pos-tagger/chinese-distsim/chinese-distsim.tagger

# ner æ­¤å¤„è®¾å®šäº†nerä½¿ç”¨çš„è¯­è¨€ã€æ¨¡å‹ï¼ˆcrfï¼‰ï¼Œç›®å‰SUTimeåªæ”¯æŒè‹±æ–‡ï¼Œä¸æ”¯æŒä¸­æ–‡ï¼Œæ‰€ä»¥è®¾ç½®ä¸ºfalseã€‚
ner.language = chinese
ner.model = edu/stanford/nlp/models/ner/chinese.misc.distsim.crf.ser.gz
ner.applyNumericClassifiers = true
ner.useSUTime = false

# regexner
ner.fine.regexner.mapping = edu/stanford/nlp/models/kbp/chinese/gazetteers/cn_regexner_mapping.tab
ner.fine.regexner.noDefaultOverwriteLabels = CITY,COUNTRY,STATE_OR_PROVINCE

# parse
parse.model = edu/stanford/nlp/models/srparser/chineseSR.ser.gz

# depparse
depparse.model    = edu/stanford/nlp/models/parser/nndep/UD_Chinese.gz
depparse.language = chinese

# coref
coref.sieves = ChineseHeadMatch, ExactStringMatch, PreciseConstructs, StrictHeadMatch1, StrictHeadMatch2, StrictHeadMatch3, StrictHeadMatch4, PronounMatch
coref.input.type = raw
coref.postprocessing = true
coref.calculateFeatureImportance = false
coref.useConstituencyTree = true
coref.useSemantics = false
coref.algorithm = hybrid
coref.path.word2vec =
coref.language = zh
coref.defaultPronounAgreement = true
coref.zh.dict = edu/stanford/nlp/models/dcoref/zh-attributes.txt.gz
coref.print.md.log = false
coref.md.type = RULE
coref.md.liberalChineseMD = false

# kbp
kbp.semgrex = edu/stanford/nlp/models/kbp/chinese/semgrex
kbp.tokensregex = edu/stanford/nlp/models/kbp/chinese/tokensregex
kbp.language = zh
kbp.model = none

# entitylink
entitylink.wikidict = edu/stanford/nlp/models/kbp/chinese/wikidict_chinese.tsv.gz
```

```java
 
.............å¼€å§‹ï¼š1605864807982
2020-11-20 17:33:28.013 [main] INFO  e.s.nlp.wordseg.ChineseDictionary - Loading Chinese dictionaries from 1 file:
2020-11-20 17:33:28.014 [main] INFO  e.s.nlp.wordseg.ChineseDictionary -   edu/stanford/nlp/models/segmenter/chinese/dict-chris6.ser.gz
2020-11-20 17:33:28.306 [main] INFO  e.s.nlp.wordseg.ChineseDictionary - Done. Unique words in ChineseDictionary is: 423200.
2020-11-20 17:33:28.428 [main] INFO  edu.stanford.nlp.wordseg.CorpusChar - Loading character dictionary file from edu/stanford/nlp/models/segmenter/chinese/dict/character_list [done].
2020-11-20 17:33:28.430 [main] INFO  e.s.nlp.wordseg.AffixDictionary - Loading affix dictionary from edu/stanford/nlp/models/segmenter/chinese/dict/in.ctb [done].
.............å¼€å§‹åˆ†æï¼š
è¢éš†å¹³
NR
è¢éš†å¹³ | analysis : {  original : PERSON, normalized : null}
è¢éš†å¹³
æ˜¯
VC
æ˜¯ | analysis : {  original : O, normalized : null}
æ˜¯
ä¸­å›½
NR
ä¸­å›½ | analysis : {  original : ORGANIZATION, normalized : null}
ä¸­å›½
ç§‘å­¦é™¢
NN
ç§‘å­¦é™¢ | analysis : {  original : ORGANIZATION, normalized : null}
ç§‘å­¦é™¢
çš„
DEG
çš„ | analysis : {  original : O, normalized : null}
çš„
é™¢å£«
NN
é™¢å£« | analysis : {  original : TITLE, normalized : null}
é™¢å£«
,
PU
, | analysis : {  original : O, normalized : null}
,
ä»–
PN
ä»– | analysis : {  original : O, normalized : null}
ä»–
äº
P
äº | analysis : {  original : O, normalized : null}
äº
2009å¹´
NT
2009å¹´ | analysis : {  original : DATE, normalized : 2009-10-XX}
2009å¹´
10æœˆ
NT
10æœˆ | analysis : {  original : DATE, normalized : 2009-10-XX}
10æœˆ
åˆ°
CC
åˆ° | analysis : {  original : O, normalized : null}
åˆ°
ä¸­å›½
NR
ä¸­å›½ | analysis : {  original : COUNTRY, normalized : null}
ä¸­å›½
å±±ä¸œçœ
NR
å±±ä¸œçœ | analysis : {  original : STATE_OR_PROVINCE, normalized : null}
å±±ä¸œçœ
ä¸œè¥å¸‚
NR
ä¸œè¥å¸‚ | analysis : {  original : CITY, normalized : null}
ä¸œè¥å¸‚
ä¸œè¥åŒº
NR
ä¸œè¥åŒº | analysis : {  original : FACILITY, normalized : null}
ä¸œè¥åŒº
æ°¸ä¹
NR
æ°¸ä¹ | analysis : {  original : FACILITY, normalized : null}
æ°¸ä¹
æœºåœº
NN
æœºåœº | analysis : {  original : FACILITY, normalized : null}
æœºåœº
é™„è¿‘
LC
é™„è¿‘ | analysis : {  original : O, normalized : null}
é™„è¿‘
æ‰¿åŒ…
VV
æ‰¿åŒ… | analysis : {  original : O, normalized : null}
æ‰¿åŒ…
äº†
AS
äº† | analysis : {  original : O, normalized : null}
äº†
ä¸€åƒ
CD
ä¸€åƒ | analysis : {  original : NUMBER, normalized : 1000}
ä¸€åƒ
äº©
M
äº© | analysis : {  original : O, normalized : null}
äº©
ç›
NN
ç› | analysis : {  original : O, normalized : null}
ç›
ç¢±åœ°
NN
ç¢±åœ° | analysis : {  original : O, normalized : null}
ç¢±åœ°
,
PU
, | analysis : {  original : O, normalized : null}
,
å¼€å§‹
VV
å¼€å§‹ | analysis : {  original : O, normalized : null}
å¼€å§‹
ç§æ¤
VV
ç§æ¤ | analysis : {  original : O, normalized : null}
ç§æ¤
æ£‰èŠ±
NN
æ£‰èŠ± | analysis : {  original : O, normalized : null}
æ£‰èŠ±
,
PU
, | analysis : {  original : O, normalized : null}
,
å¹´äº§é‡
NN
å¹´äº§é‡ | analysis : {  original : O, normalized : null}
å¹´äº§é‡
è¾¾åˆ°
VV
è¾¾åˆ° | analysis : {  original : O, normalized : null}
è¾¾åˆ°
ä¸€ä¸‡
CD
ä¸€ä¸‡ | analysis : {  original : NUMBER, normalized : 10000}
ä¸€ä¸‡
å¨
M
å¨ | analysis : {  original : O, normalized : null}
å¨
,
PU
, | analysis : {  original : O, normalized : null}
,
å“ˆå“ˆ
IJ
å“ˆå“ˆ | analysis : {  original : O, normalized : null}
å“ˆå“ˆ
,
PU
, | analysis : {  original : O, normalized : null}
,
åæ­£
AD
åæ­£ | analysis : {  original : O, normalized : null}
åæ­£
æ££ç¦
NR
æ££ç¦ | analysis : {  original : PERSON, normalized : null}
æ££ç¦
è¯´
VV
è¯´ | analysis : {  original : O, normalized : null}
è¯´
çš„
DEC
çš„ | analysis : {  original : O, normalized : null}
çš„
æ˜¯
VC
æ˜¯ | analysis : {  original : O, normalized : null}
æ˜¯
å‡
JJ
å‡ | analysis : {  original : O, normalized : null}
å‡
çš„
DEG
çš„ | analysis : {  original : O, normalized : null}
çš„
,
PU
, | analysis : {  original : O, normalized : null}
,
é€—
VV
é€— | analysis : {  original : O, normalized : null}
é€—
ä½ 
PN
ä½  | analysis : {  original : O, normalized : null}
ä½ 
ç©å„¿
VV
ç©å„¿ | analysis : {  original : O, normalized : null}
ç©å„¿
,
PU
, | analysis : {  original : O, normalized : null}
,
æ˜å¤©
NT
æ˜å¤© | analysis : {  original : DATE, normalized : XXXX-XX-XX}
æ˜å¤©
ä¸‹åˆ
NT
ä¸‹åˆ | analysis : {  original : TIME, normalized : null}
ä¸‹åˆ
2ç‚¹
NT
2ç‚¹ | analysis : {  original : TIME, normalized : null}
2ç‚¹
æ¥
VV
æ¥ | analysis : {  original : O, normalized : null}
æ¥
æˆ‘
PN
æˆ‘ | analysis : {  original : O, normalized : null}
æˆ‘
å®¶
NN
å®¶ | analysis : {  original : O, normalized : null}
å®¶
åƒé¥­
VV
åƒé¥­ | analysis : {  original : O, normalized : null}
åƒé¥­
å§
SP
å§ | analysis : {  original : O, normalized : null}
å§
ã€‚
PU
ã€‚ | analysis : {  original : O, normalized : null}
ã€‚
æ££ç¦
NR
æ££ç¦ | analysis : {  original : PERSON, normalized : null}
æ££ç¦
æ˜¯
VC
æ˜¯ | analysis : {  original : O, normalized : null}
æ˜¯
å±±ä¸œ
NR
å±±ä¸œ | analysis : {  original : ORGANIZATION, normalized : null}
å±±ä¸œ
å¤§å­¦
NN
å¤§å­¦ | analysis : {  original : ORGANIZATION, normalized : null}
å¤§å­¦
æ¯•ä¸š
VV
æ¯•ä¸š | analysis : {  original : O, normalized : null}
æ¯•ä¸š
çš„
DEC
çš„ | analysis : {  original : O, normalized : null}
çš„
,
PU
, | analysis : {  original : O, normalized : null}
,
ç›®å‰
NT
ç›®å‰ | analysis : {  original : DATE, normalized : null}
ç›®å‰
åœ¨
P
åœ¨ | analysis : {  original : O, normalized : null}
åœ¨
ç™¾åº¦
NR
ç™¾åº¦ | analysis : {  original : ORGANIZATION, normalized : null}
ç™¾åº¦
åš
VV
åš | analysis : {  original : O, normalized : null}
åš
java
NN
java | analysis : {  original : O, normalized : null}
java
å¼€å‘
NN
å¼€å‘ | analysis : {  original : O, normalized : null}
å¼€å‘
,
PU
, | analysis : {  original : O, normalized : null}
,
ä½ç½®
NN
ä½ç½® | analysis : {  original : O, normalized : null}
ä½ç½®
æ˜¯
VC
æ˜¯ | analysis : {  original : O, normalized : null}
æ˜¯
ä¸œåŒ—
NN
ä¸œåŒ— | analysis : {  original : LOCATION, normalized : null}
ä¸œåŒ—
æ—º
VV
æ—º | analysis : {  original : O, normalized : null}
æ—º
ä¸œè·¯
NR
ä¸œè·¯ | analysis : {  original : O, normalized : null}
ä¸œè·¯
102
CD
102 | analysis : {  original : NUMBER, normalized : 102}
102
å·é™¢
NN
å·é™¢ | analysis : {  original : O, normalized : null}
å·é™¢
,
PU
, | analysis : {  original : O, normalized : null}
,
æ‰‹æœºå·
NN
æ‰‹æœºå· | analysis : {  original : O, normalized : null}
æ‰‹æœºå·
143667788
CD
143667788 | analysis : {  original : NUMBER, normalized : 14366778890}
143667788
90
CD
90 | analysis : {  original : NUMBER, normalized : 14366778890}
90
å¥å­çš„è§£ææ ‘:
(ROOT
  (NP
    (NP (NR è¢éš†å¹³))
    (PRN
      (IP
        (VP (VC æ˜¯)
          (NP
            (DNP
              (NP (NR ä¸­å›½) (NN ç§‘å­¦é™¢))
              (DEG çš„))
            (NP (NN é™¢å£«))))
        (PU ,)
        (IP
          (NP (PN ä»–))
          (VP
            (PP (P äº)
              (LCP
                (NP (NT 2009å¹´) (NT 10æœˆ)
                  (CC åˆ°)
                  (NP (NR ä¸­å›½) (NR å±±ä¸œçœ) (NR ä¸œè¥å¸‚) (NR ä¸œè¥åŒº) (NR æ°¸ä¹) (NN æœºåœº)))
                (LC é™„è¿‘)))
            (VP (VV æ‰¿åŒ…) (AS äº†)
              (IP
                (NP
                  (QP (CD ä¸€åƒ)
                    (CLP (M äº©)))
                  (NP (NN ç›) (NN ç¢±åœ°)))
                (PU ,)
                (VP (VV å¼€å§‹)
                  (VP (VV ç§æ¤)
                    (IP
                      (IP
                        (NP (NN æ£‰èŠ±))
                        (PU ,)
                        (IP
                          (NP (NN å¹´äº§é‡))
                          (VP (VV è¾¾åˆ°)
                            (QP (CD ä¸€ä¸‡)
                              (CLP (M å¨)))))
                        (PU ,)
                        (FLR (IJ å“ˆå“ˆ))
                        (PU ,)
                        (IP
                          (NP
                            (CP
                              (IP
                                (ADVP (AD åæ­£))
                                (NP (NR æ££ç¦))
                                (VP (VV è¯´)))
                              (DEC çš„)))
                          (VP (VC æ˜¯)
                            (NP
                              (DNP
                                (ADJP (JJ å‡))
                                (DEG çš„)))))
                        (PU ,)
                        (IP
                          (VP (VV é€—)
                            (NP (PN ä½ ))
                            (IP
                              (VP (VV ç©å„¿)))))
                        (PU ,)
                        (CP
                          (IP
                            (NP (NT æ˜å¤©) (NT ä¸‹åˆ) (NT 2ç‚¹))
                            (VP
                              (VP (VV æ¥)
                                (NP (PN æˆ‘) (NN å®¶)))
                              (VP (VV åƒé¥­))))
                          (SP å§))
                        (PU ã€‚))
                      (NP (NR æ££ç¦))
                      (VP (VC æ˜¯)
                        (NP
                          (CP
                            (IP
                              (VP
                                (NP (NR å±±ä¸œ) (NN å¤§å­¦))
                                (VP (VV æ¯•ä¸š))))
                            (DEC çš„))
                          (PU ,)
                          (PRN
                            (IP
                              (IP
                                (VP
                                  (NP (NT ç›®å‰))
                                  (PP (P åœ¨)
                                    (NP (NR ç™¾åº¦)))
                                  (VP (VV åš)
                                    (NP (NN java) (NN å¼€å‘)))))
                              (PU ,)
                              (NP (NN ä½ç½®))
                              (VP (VC æ˜¯)
                                (IP
                                  (NP (NN ä¸œåŒ—))
                                  (VP (VV æ—º)
                                    (NP
                                      (NP (NR ä¸œè·¯))
                                      (QP (CD 102))
                                      (NP (NN å·é™¢)))))))))))))))))
        (PU ,)
        (IP
          (IP
            (NP (NN æ‰‹æœºå·))
            (VP
              (QP (CD 143667788))))
          (QP (CD 90)))))))
å¥å­çš„ä¾èµ–å›¾
root(ROOT-0, è¢éš†å¹³-1)
cop(é™¢å£«-6, æ˜¯-2)
compound:nn(ç§‘å­¦é™¢-4, ä¸­å›½-3)
nmod:assmod(é™¢å£«-6, ç§‘å­¦é™¢-4)
case(ç§‘å­¦é™¢-4, çš„-5)
parataxis:prnmod(è¢éš†å¹³-1, é™¢å£«-6)
punct(é™¢å£«-6, ,-7)
nsubj(æ‰¿åŒ…-20, ä»–-8)
case(10æœˆ-11, äº-9)
compound:nn(10æœˆ-11, 2009å¹´-10)
nmod:prep(æ‰¿åŒ…-20, 10æœˆ-11)
cc(10æœˆ-11, åˆ°-12)
compound:nn(æœºåœº-18, ä¸­å›½-13)
compound:nn(æœºåœº-18, å±±ä¸œçœ-14)
compound:nn(æœºåœº-18, ä¸œè¥å¸‚-15)
compound:nn(æœºåœº-18, ä¸œè¥åŒº-16)
compound:nn(æœºåœº-18, æ°¸ä¹-17)
dep(10æœˆ-11, æœºåœº-18)
case(10æœˆ-11, é™„è¿‘-19)
conj(é™¢å£«-6, æ‰¿åŒ…-20)
aux:asp(æ‰¿åŒ…-20, äº†-21)
nummod(ç¢±åœ°-25, ä¸€åƒ-22)
mark:clf(ä¸€åƒ-22, äº©-23)
compound:nn(ç¢±åœ°-25, ç›-24)
nsubj(ç§æ¤-28, ç¢±åœ°-25)
punct(ç§æ¤-28, ,-26)
xcomp(ç§æ¤-28, å¼€å§‹-27)
ccomp(æ‰¿åŒ…-20, ç§æ¤-28)
nsubj(è¾¾åˆ°-32, æ£‰èŠ±-29)
punct(è¾¾åˆ°-32, ,-30)
nsubj(è¾¾åˆ°-32, å¹´äº§é‡-31)
conj(æ¯•ä¸š-63, è¾¾åˆ°-32)
nmod:range(è¾¾åˆ°-32, ä¸€ä¸‡-33)
mark:clf(ä¸€ä¸‡-33, å¨-34)
punct(è¾¾åˆ°-32, ,-35)
dep(è¾¾åˆ°-32, å“ˆå“ˆ-36)
punct(è¾¾åˆ°-32, ,-37)
advmod(è¯´-40, åæ­£-38)
nsubj(è¯´-40, æ££ç¦-39)
nsubj(å‡-43, è¯´-40)
mark(è¯´-40, çš„-41)
cop(å‡-43, æ˜¯-42)
conj(è¾¾åˆ°-32, å‡-43)
case(å‡-43, çš„-44)
punct(è¾¾åˆ°-32, ,-45)
conj(è¾¾åˆ°-32, é€—-46)
dobj(é€—-46, ä½ -47)
ccomp(é€—-46, ç©å„¿-48)
punct(è¾¾åˆ°-32, ,-49)
compound:nn(2ç‚¹-52, æ˜å¤©-50)
compound:nn(2ç‚¹-52, ä¸‹åˆ-51)
nmod:tmod(æ¥-53, 2ç‚¹-52)
dep(è¾¾åˆ°-32, æ¥-53)
nmod:poss(å®¶-55, æˆ‘-54)
dobj(æ¥-53, å®¶-55)
conj(æ¥-53, åƒé¥­-56)
discourse(æ¥-53, å§-57)
punct(è¾¾åˆ°-32, ã€‚-58)
nsubj(æ¯•ä¸š-63, æ££ç¦-59)
cop(æ¯•ä¸š-63, æ˜¯-60)
compound:nn(å¤§å­¦-62, å±±ä¸œ-61)
dep(æ¯•ä¸š-63, å¤§å­¦-62)
ccomp(ç§æ¤-28, æ¯•ä¸š-63)
mark(æ¯•ä¸š-63, çš„-64)
punct(æ¯•ä¸š-63, ,-65)
nmod:tmod(åš-69, ç›®å‰-66)
case(ç™¾åº¦-68, åœ¨-67)
nmod:prep(åš-69, ç™¾åº¦-68)
dep(æ—º-76, åš-69)
compound:nn(å¼€å‘-71, java-70)
dobj(åš-69, å¼€å‘-71)
punct(æ—º-76, ,-72)
nsubj(æ—º-76, ä½ç½®-73)
cop(æ—º-76, æ˜¯-74)
nsubj(æ—º-76, ä¸œåŒ—-75)
parataxis:prnmod(æ¯•ä¸š-63, æ—º-76)
nmod(å·é™¢-79, ä¸œè·¯-77)
dep(å·é™¢-79, 102-78)
dobj(æ—º-76, å·é™¢-79)
punct(é™¢å£«-6, ,-80)
nsubj(143667788-82, æ‰‹æœºå·-81)
conj(é™¢å£«-6, 143667788-82)
dep(143667788-82, 90-83)

The analysis lasts 1959 seconds * 1000
Chain 5 
  "æ££ç¦" in sentence 1, i.e., 0-based character offsets [75, 77)
  "æ££ç¦" in sentence 1, i.e., 0-based character offsets [101, 103)
Chain 11 
  "ä¸­å›½ ç§‘å­¦é™¢ çš„ é™¢å£«" in sentence 1, i.e., 0-based character offsets [4, 12)
  "ä»–" in sentence 1, i.e., 0-based character offsets [13, 14)

Process finished with exit code 0

```

